{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "pd.options.display.max_colwidth = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all the names of the 34 unsafe ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unsafe = pd.read_csv('unsafe.csv')\n",
    "print(df_unsafe.shape)\n",
    "df_unsafe[:1]['ingredient other_names'.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hash or dictionary lookup table for ingredient names\n",
    "# A hash table is essentially a dictionary; it maps a key to a value.\n",
    "# We use HASH here for fast checking \n",
    "# whether a word occurred in Amazon product description is in\n",
    "# the hash table (or dictionary) of ingredient\n",
    "\n",
    "import re\n",
    "\n",
    "unsafe_name_hash = {}\n",
    "for ingredient, other_names in zip(df_unsafe['ingredient'], df_unsafe['other_names']):\n",
    "    unsafe_name_hash[ingredient] = True\n",
    "    for name in other_names.split(', '):\n",
    "        unsafe_name_hash[name] = True\n",
    "print(len(unsafe_name_hash))\n",
    "\n",
    "# normalize names by removing non-alphanumeric characters\n",
    "# for example, we will convert Chuan-wu to Chuanwu\n",
    "unsafe_name_hash_normalized = {}\n",
    "for name in unsafe_name_hash:\n",
    "    unsafe_name_normalized = re.sub(r'\\W+', '', name.lower())  # \\w: a-zA-Z0-9 and _,  \\W non of the \\w set\n",
    "    unsafe_name_hash_normalized[unsafe_name_normalized] = True\n",
    "print(len(unsafe_name_hash_normalized))\n",
    "print(list(unsafe_name_hash_normalized)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the longest names (based on how many words or parts in a name)\n",
    "# for example, \"chuan wu\" has two parts, so its size is 2.\n",
    "\n",
    "longest_name = \"\"\n",
    "longest_name_len = 0\n",
    "for name in unsafe_name_hash:  # same as: for name in name_hash.keys()\n",
    "    name_parts = name.split()\n",
    "    name_parts_len = len(name_parts)\n",
    "    if name_parts_len > longest_name_len:\n",
    "        longest_name_len = name_parts_len\n",
    "        longest_name = name\n",
    "print(f\"longest name: {longest_name}\")\n",
    "print(f\"num of parts: {longest_name_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning time: JSON (Amazon data is represented in this format)\n",
    "\n",
    "- construct a sort of complicated dictionary\n",
    "- save the dictionary to a json file or string\n",
    "- load a dictionary from a json file or string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instructions - run the instructions here\n",
    "```\n",
    "student = {\"id\":123, \n",
    "          \"name\": {\"first_name\": \"Joe\", \"last_name\": \"Smith\"},\n",
    "          \"courses\": [\n",
    "              {\"name\": \"Biology\", \"teacher\": \"Charles Darwin\"},\n",
    "              {\"name\": \"Physics\", \"teacher\": \"Albert Einstein\"},\n",
    "              {\"name\": \"Math\", \"teacher\": \"Carl Friedrich Gauss\"}\n",
    "          ]}\n",
    "\n",
    "type(student)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(student)\n",
    "```\n",
    "\n",
    "```\n",
    "import json\n",
    "s = json.dumps(student)\n",
    "\n",
    "type(s)\n",
    "\n",
    "o = json.loads(s)\n",
    "\n",
    "type(o)\n",
    "```\n",
    "\n",
    "```\n",
    "json.dump(student, open('/tmp/a.json', 'w'))\n",
    "\n",
    "student2 = json.load(open('/tmp/a.json', 'w'))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "amazon_health_json_fpath = \"../data/amazon_sample_aconite.json\"\n",
    "asin_desc = {}\n",
    "for line in open(amazon_health_json_fpath).readlines():\n",
    "    print(line[:300])\n",
    "    record = json.loads(line)\n",
    "    pprint(record)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast   # ast: abstract syntax tree\n",
    "\n",
    "asin_desc = {}\n",
    "amazon_health_json_fpath = \"../data/amazon_sample_aconite.json\"\n",
    "\n",
    "for line in open(amazon_health_json_fpath).readlines():\n",
    "    record = ast.literal_eval(line)\n",
    "    pprint(record)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record['categories']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://ecx.images-amazon.com/images/I/413Tm3QXjBL._SY300_.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download file meta_Health_and_Personal_Care.json\n",
    "\n",
    "from: https://textmining.ischool.syr.edu/share/kelly/\n",
    "\n",
    "save it to: firstdonoharm/data      (you may need to create a new folder \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast   # ast: abstract syntax tree\n",
    "\n",
    "amazon_health_json_fpath = \"../data/amazon_sample_aconite.json\"\n",
    "# amazon_health_json_fpath = \"../data/meta_Health_and_Personal_Care.json\"\n",
    "\n",
    "asin_description = {}\n",
    "for line in open(amazon_health_json_fpath).readlines():\n",
    "    record = ast.literal_eval(line)\n",
    "    asin = record['asin']\n",
    "    categories = record['categories']\n",
    "#     if not \"Vitamins & Dietary Supplements\" in categories[0]:  # for simplicity, we only consider the first list\n",
    "#         continue\n",
    "        \n",
    "    title = record['title']\n",
    "    desc = record['description']\n",
    "    print(f\"[TITLE] {title}\\n[ASIN] {asin}\\n[LINK] https://www.amazon.com/dp/{asin}\\n\\n{desc}\\n\\n\")\n",
    "    asin_description[asin] = title + \" \" + desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modify the above part to avoid the error \n",
    "```\n",
    "missing_cnt = 0\n",
    "for line in open(amazon_health_json_fpath).readlines():\n",
    "    record = ast.literal_eval(line)\n",
    "    asin = record['asin']\n",
    "    categories = record['categories']\n",
    "    if not \"Vitamins & Dietary Supplements\" in categories[0]:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        title = record['title']\n",
    "        desc = record['description']\n",
    "        asin_description[asin] = title + \" \" + desc\n",
    "    except:\n",
    "        missing_cnt += 1\n",
    "\n",
    "print(f'missing_cnt: {missing_cnt}')\n",
    "```\n",
    "\n",
    "Also, add `%%time` at the beginning a cell to find out the time used to execute the cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unsafe_ingredient_name_in_amazon_text(desc, unsafe_name_hash):\n",
    "    desc_normalized = re.sub(r'\\W', ' ', desc.lower())\n",
    "    found_names = {}\n",
    "    for w in desc_normalized.split():\n",
    "        if w in unsafe_name_hash and w not in found_names:\n",
    "            found_names[w] = True\n",
    "    return list(found_names.keys())\n",
    "\n",
    "\n",
    "asin_unsafe_names_found = {}\n",
    "for asin, desc in asin_description.items():\n",
    "    unsafe_names_found = find_unsafe_ingredient_name_in_amazon_text(desc, unsafe_name_hash_normalized)\n",
    "    if len(unsafe_unsafe_names_found) > 0:\n",
    "        asin_unsafe_names_found[asin] = unsafe_names_found\n",
    "\n",
    "print(len(asin_unsafe_names_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin_unsafe_names_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(asin_unsafe_names_found.values())\n",
    "asins = list(asin_unsafe_names_found.keys())\n",
    "data = {'asin': asins, 'unsafe_names': names}\n",
    "\n",
    "df_amazon = pd.DataFrame(data)\n",
    "df_amazon.to_csv('/tmp/a.csv', index=False)\n",
    "print(df_amazon.shape)\n",
    "df_amazon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# HOMEWORK: \n",
    "\n",
    "using the downloaded large amazon data to rerun the above code to generate a csv file, \n",
    "and take a look at the results. Something may need to do to improve our result. \n",
    "What can we do to improve the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate an HTML page that contains links to relevant Amazon product page\n",
    "\n",
    "For example, for the above product whose ASIN is B00008CMQ2,\n",
    "we can construct a link: https://www.amazon.com/dp/B00008CMQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need more processing for special HTML entities\n",
    "\n",
    "For example, in the original display\n",
    "```\n",
    "1. \"&gt;\" is \">\"\n",
    "2. \"&egrave;\" is \"è\" (which will be converted to letter 'e' after removing accent)\n",
    "```\n",
    "\n",
    "After HTML rendering:\n",
    "\n",
    "1. \"&gt;\" is \">\"\n",
    "2. \"&egrave;\" is \"è\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "s = 'Bulbif&egrave;re'\n",
    "s = html.unescape(s)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "\n",
    "s = unidecode.unidecode(s)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.other_names = df.other_names.apply(lambda s: unidecode.unidecode(html.unescape(s)))\n",
    "df.iloc[28]['other_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a HTML page for easy browse and exploration\n",
    "\n",
    "A third way to make a string: a multi-line string with \n",
    "\"\"\"\n",
    "your \n",
    "multi-line\n",
    "str \n",
    "here\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = \"\"\"\n",
    "<style>\n",
    "body {width: 960px; margin:auto; margin-top:10px; font-family:arial}\n",
    "a {text-decoration: none; font-size:120%; white-space:nowrap}\n",
    "table {border-collapse: collapse}\n",
    "td {border-right: 1px solid #eee}\n",
    "</style>\n",
    "<table cellpadding=8>\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "no = 1\n",
    "for ingredient, other_names, href, side_effects in zip(df.ingredient, df.other_names, df.href, df.side_effects):\n",
    "#     side_effects = re.sub(r'\\s+(,|\\.)', r'\\1', side_effects)\n",
    "    \n",
    "    row = f\"\"\"<tr valign=top>\n",
    "    <td>{no}\n",
    "    <td align=right><a target=_blank href=\\\"{href}\\\">{ingredient}</a>\n",
    "    <td>{side_effects}\n",
    "    <td>{other_names}\n",
    "    </tr>\"\"\"\n",
    "    out += row\n",
    "    no += 1\n",
    "    \n",
    "html_outfile = '/tmp/a.html'\n",
    "open(html_outfile, 'w').write(out)\n",
    "html_outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Regular Expressions (optional)\n",
    "\n",
    "check https://developers.google.com/edu/python/regular-expressions\n",
    "for more on Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = \"Aga is UNSAFE when taken by mouth . It sleepiness , confusion, dizziness  , delirium    , and death   .\"\n",
    "s.replace(' ,', ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re  # re: Regular Expression\n",
    "\n",
    "re.sub(r' +,', ',', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meta-characters, need to use \\ to get rid of the special meaning\n",
    "```\n",
    "\n",
    ". ^ $ * + ? { [ ] \\ | ( ) \n",
    "\n",
    "```\n",
    "\n",
    "Their special meaning\n",
    "```\n",
    ". => match any character (except new line)\n",
    "  e.g., \n",
    "\n",
    "^ => match the beginning\n",
    "\n",
    "* => repeat the previous character or a block any times (that is, zero or more times)\n",
    "\n",
    "+ => repeat the previous character or a block at least once\n",
    "\n",
    "? => match or not match the previous character or a block\n",
    "\n",
    "\\ => escape the special meaning\n",
    "\n",
    "| => or\n",
    "\n",
    "( ) => define a block, or something you want to extract\n",
    "\n",
    "[ ] => \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.sub(r' +.', '.', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.sub(r' +\\.', '.', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.sub(r' +(\\.|,)', '.', s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
